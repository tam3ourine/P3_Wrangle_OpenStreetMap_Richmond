{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: QUERIES IN SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Prep: Import Cleaned CSV to SQL Database\n",
    "After being cleaned and reformatted as CSV files, the data is imported to the SQL database for querying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Nodes_tags.csv to nodes_tags table in richmond_sample.db #\n",
    "############################################################\n",
    "\n",
    "#1. Import the modules that you will need:\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "#2. Connect to the database (if it doesn't exist, it will be created in the folder that your notebook is in):\n",
    "sqlite_file = 'richmond_sample.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "#3. Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "#4. Create the table, specifying the column names and data types:\n",
    "# in the case of'nodes_tags.csv' as an example, it has columns: 'id, key, value,type'\n",
    "cur.execute('''CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT,type TEXT)''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'],i['value'], i['type']) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#7. check that the data imported correctly\n",
    "cur.execute('SELECT * FROM nodes_tags')\n",
    "all_rows = cur.fetchall()\n",
    "print('1):')\n",
    "pprint (all_rows)\n",
    "\n",
    "#8. close the connection:\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('nodes_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"), i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Nodes.csv to nodes table in richmond_sample.db #\n",
    "############################################################\n",
    "\n",
    "#1. Import the modules that you will need:\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "#2. Connect to the database (if it doesn't exist, it will be created in the folder that your notebook is in):\n",
    "sqlite_file = 'richmond_sample.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "#3. Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "#4. Create the table, specifying the column names and data types:\n",
    "# in the case of'nodes_tags.csv' as an example, it has columns: 'id, key, value,type'\n",
    "cur.execute('''CREATE TABLE nodes(id INTEGER, lat FLOAT, lon FLOAT, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TIMESTAMP)''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['lat'],i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#7. check that the data imported correctly\n",
    "cur.execute('SELECT * FROM nodes')\n",
    "all_rows = cur.fetchall()\n",
    "print('1):')\n",
    "pprint (all_rows)\n",
    "\n",
    "#8. close the connection:\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### I accidentally added the ways info into nodes so I'll have to re-add a nodes table to make sure, calling it nodes_2\n",
    "\n",
    "#4. Create the table, specifying the column names and data types:\n",
    "# in the case of'nodes_tags.csv' as an example, it has columns: 'id, key, value,type'\n",
    "cur.execute('''CREATE TABLE nodes_2(id INTEGER, lat FLOAT, lon FLOAT, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TIMESTAMP)''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['lat'],i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes_2(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# ways.csv to ways table in richmond_sample.db #\n",
    "############################################################\n",
    "\n",
    "#1. Import the modules that you will need:\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "#2. Connect to the database (if it doesn't exist, it will be created in the folder that your notebook is in):\n",
    "sqlite_file = 'richmond_sample.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "#3. Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "#4. Create the table, specifying the column names and data types:\n",
    "# in the case of'nodes_tags.csv' as an example, it has columns: 'id, key, value,type'\n",
    "cur.execute('''CREATE TABLE ways(id INTEGER, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TIMESTAMP)''')\n",
    "# commit the changes \n",
    "conn.commit()\n",
    "\n",
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO nodes(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# #7. check that the data imported correctly\n",
    "# cur.execute('SELECT * FROM ways')\n",
    "# all_rows = cur.fetchall()\n",
    "# print('1):')\n",
    "# pprint (all_rows)\n",
    "\n",
    "#8. close the connection:\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### In the previous code, I accidentally added the ways info to the nodes tables, so I'll have to redo it\n",
    "\n",
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# #7. check that the data imported correctly\n",
    "# cur.execute('SELECT * FROM ways')\n",
    "# all_rows = cur.fetchall()\n",
    "# print('1):')\n",
    "# pprint (all_rows)\n",
    "\n",
    "#8. close the connection:\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table ways_tags_2 already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a6ea1fbf174e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#4. Create the table, specifying the column names and data types:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# in the case of'nodes_tags.csv' as an example, it has columns: 'id, key, value,type'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'''CREATE TABLE ways_tags_2(id INTEGER, key TEXT, value TEXT, type TEXT)'''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# commit the changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: table ways_tags_2 already exists"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# ways_tags.csv to ways_tags_2 table in richmond_sample.db #\n",
    "############################################################\n",
    "\n",
    "#1. Import the modules that you will need:\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "#2. Connect to the database (if it doesn't exist, it will be created in the folder that your notebook is in):\n",
    "sqlite_file = 'richmond_sample.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "#3. Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "#4. Create the table, specifying the column names and data types:\n",
    "# in the case of'nodes_tags.csv' as an example, it has columns: 'id, key, value,type'\n",
    "cur.execute('''CREATE TABLE ways_tags_2(id INTEGER, key TEXT, value TEXT, type TEXT)''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"), i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_tags_2(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# #7. check that the data imported correctly\n",
    "# cur.execute('SELECT * FROM ways_tags')\n",
    "# all_rows = cur.fetchall()\n",
    "# print('1):')\n",
    "# pprint (all_rows)\n",
    "\n",
    "#8. close the connection:\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways_tags.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"), i['key'].decode(\"utf-8\"), i['value'].decode(\"utf-8\"), i['type'].decode(\"utf-8\")) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_tags_2(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# ways_nodes.csv to ways_nodes table in richmond_sample.db #\n",
    "############################################################\n",
    "\n",
    "#1. Import the modules that you will need:\n",
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "#2. Connect to the database (if it doesn't exist, it will be created in the folder that your notebook is in):\n",
    "sqlite_file = 'richmond_sample.db'    # name of the sqlite database file\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "#3. Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "#4. Create the table, specifying the column names and data types:\n",
    "# in the case of'nodes_tags.csv' as an example, it has columns: 'id, key, value,type'\n",
    "cur.execute('''CREATE TABLE ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)''')\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "#5. Read in the csv file as a dictionary, format the\n",
    "# data as a list of tuples:\n",
    "with open('ways_nodes.csv','rb') as fin:\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "    \n",
    "#6. Insert the formatted data\n",
    "cur.executemany(\"INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# #7. check that the data imported correctly\n",
    "# cur.execute('SELECT * FROM ways_tags')\n",
    "# all_rows = cur.fetchall()\n",
    "# print('1):')\n",
    "# pprint (all_rows)\n",
    "\n",
    "#8. close the connection:\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1: Find Overview\n",
    "Find .tables, .schema, and statistical overviews such as number of nodes, number of ways, number of unique users, top ten contributing users, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'nodes_tags',), (u'nodes',), (u'ways',), (u'ways_tags',), (u'ways_tags_2',), (u'ways_nodes',), (u'nodes_2',)]\n"
     ]
    }
   ],
   "source": [
    "# Find .tables\n",
    "sqlite_file = 'richmond_sample.db'\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "QUERY = \"select name from sqlite_master where type = 'table';\" # query .tables\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT,type TEXT)',)]\n"
     ]
    }
   ],
   "source": [
    "# Find .schema\n",
    "QUERY = \"select sql from sqlite_master where type = 'table' and name = 'nodes_tags';\" # query .schema nodes_tags\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(332055,)]\n"
     ]
    }
   ],
   "source": [
    "# Find number of nodes: * error table, disregard **\n",
    "QUERY = \"SELECT COUNT(*) FROM nodes;\"\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(300985,)]\n"
     ]
    }
   ],
   "source": [
    "# Find number of nodes_2: *I accidentally added the wrong info to nodes table, so use nodes_2\n",
    "QUERY = \"SELECT COUNT(*) FROM nodes_2;\"\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(31070,)]\n"
     ]
    }
   ],
   "source": [
    "# Find number of ways:\n",
    "QUERY = \"SELECT COUNT(*) FROM ways;\"\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(351,)]\n"
     ]
    }
   ],
   "source": [
    "# Find number of unique users:\n",
    "QUERY = \"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes_2 UNION ALL SELECT uid FROM ways) e;\"\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'woodpeck_fixbot', 127228), (u'RVA_101', 61305), (u'CynicalDooDad', 33881), (u'Omnific', 25616), (u'gpstrails', 19566), (u'42429', 10039), (u'TIGERcnl', 5882), (u'taber', 5861), (u'bot-mode', 5455), (u'daddyklee', 4669)]\n"
     ]
    }
   ],
   "source": [
    "# Find top 10 contributing users:\n",
    "QUERY = '''\n",
    "SELECT e.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes_2 UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(74,)]\n"
     ]
    }
   ],
   "source": [
    "# Number of unique users appearing only once\n",
    "QUERY = '''\n",
    "SELECT COUNT(*) \n",
    "FROM\n",
    "    (SELECT e.user, COUNT(*) as num FROM \n",
    "    (SELECT user FROM nodes_2 UNION ALL SELECT user FROM ways) e \n",
    "    GROUP BY e.user HAVING num=1)  u;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'23220', 47), (u'23219', 32), (u'23059', 16), (u'23060', 12), (u'23230', 12), (u'23221', 10), (u'23223', 7), (u'23235', 5), (u'23112', 2), (u'23114', 2), (u'23116', 2), (u'23150', 2), (u'23224', 2), (u'23236', 2), (u'23832', 2), (u'19335', 1), (u'23221-3504', 1), (u'23222', 1), (u'23226', 1), (u'23227-1107', 1), (u'23233', 1), (u'23236-3103', 1), (u'23238', 1), (u'23284', 1), (u'23298', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Top zipcodes\n",
    "QUERY = '''\n",
    "SELECT tags.value, COUNT(*) as count \n",
    "FROM (SELECT * FROM nodes_tags \n",
    "      UNION ALL \n",
    "      SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key='postcode'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Richmond', 135), (u'Glen Allen', 28), (u'Midlothian', 4), (u'Bon Air', 2), (u'Chesterfield', 2), (u'Sandston', 2), (u'1', 1), (u'3', 1), (u'Downingtown ', 1), (u'None', 1), (u'glen Allen', 1), (u'no', 1), (u'richmond', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Top Cities\n",
    "QUERY = '''\n",
    "SELECT tags.value, COUNT(*) as count \n",
    "FROM (SELECT * FROM nodes_tags UNION ALL \n",
    "      SELECT * FROM ways_tags) tags\n",
    "WHERE tags.key LIKE '%city'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'restaurant', 212), (u'place_of_worship', 154), (u'school', 119), (u'fast_food', 94), (u'fuel', 46), (u'bank', 39), (u'cafe', 32), (u'grave_yard', 32), (u'fire_station', 27), (u'pharmacy', 24)]\n"
     ]
    }
   ],
   "source": [
    "# Top ten appearing amenities\n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE key='amenity'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'tree', 1722), (u'peak', 3), (u'cliff', 1), (u'wetland', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Top ten 'natural' keys\n",
    "QUERY = '''\n",
    "SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE key='natural'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Starbucks', 10), (u'Dunkin Donuts', 2), (u'Tropical Smoothie Cafe', 2), (u'821 Cafe', 1), (u'Bell Cafe', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Top five cafes\n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='cafe') i\n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key='name' \n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'american', 8), (u'chinese', 7), (u'italian', 7), (u'mexican', 6), (u'sushi', 4), (u'pizza', 3), (u'regional', 3), (u'thai', 3), (u'ice_cream', 2), (u'japanese', 2), (u'sandwich', 2), (u'asian', 1), (u'bbq', 1), (u'bistro', 1), (u'breakfast', 1), (u'burger', 1), (u'french', 1), (u'indian', 1), (u'korean', 1), (u'mediterranean', 1), (u'seafood', 1), (u'southern', 1), (u'tacos', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Top ten cuisines\n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key='cuisine'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'23220', 17), (u'23219', 9), (u'23230', 3), (u'23221', 2), (u'23223', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Zipcodes with most restaurants\n",
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "    ON nodes_tags.id=i.id\n",
    "WHERE nodes_tags.key='postcode' \n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "cur.execute(QUERY)\n",
    "result = cur.fetchall()\n",
    "print result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
